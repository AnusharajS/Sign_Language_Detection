{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KuLTWrCNdofH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n","from keras.utils import np_utils\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler,LabelEncoder\n","from sklearn.metrics import classification_report,confusion_matrix\n","import os\n","import random\n","import shutil\n","from shutil import copyfile\n","from keras.preprocessing.image import ImageDataGenerator\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"T0u42ErXeEJV"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"a7XHrz38efh9"},"outputs":[],"source":["values = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3KBJZ1VSefel"},"outputs":[],"source":["main_dir='D:\\ML_Data/' #ML mini project path\n","#source and dest dir\n","# source_dir=main_dir+'Augmented_images/'\n","dest_dir=main_dir+'signs_resized/'\n","train_dir=dest_dir+'training/'\n","val_dir=dest_dir+'validation/'\n","\n","# for dir1 in values:\n","#     path=os.path.join(train_dir,dir1)\n","#     os.mkdir(path)\n","\n","# for dir1 in values:\n","#     path=os.path.join(val_dir,dir1)\n","#     os.mkdir(path)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Configured TensorFlow to use GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"]}],"source":["\n","# Specify the GPU device to use\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Restrict TensorFlow to use only the first GPU\n","    tf.config.set_visible_devices(gpus[0], 'GPU')\n","    # Allow memory growth to prevent out-of-memory errors\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","    print('Configured TensorFlow to use GPU:', gpus[0])\n","  except RuntimeError as e:\n","    print(e)\n","else:\n","  print('No GPU detected, using CPU instead.')\n","\n","# Your TensorFlow code here...\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"E1muSSzbefcR"},"outputs":[],"source":["# #all directories\n","# main_dir='/content/drive/MyDrive/ML Mini project/'\n","\n","# source_dir=main_dir+'Augmented_images/'\n","# dest_dir=main_dir+'Final_imgs/'\n","\n","\n","# train_dir=dest_dir+'training/'\n","# val_dir=dest_dir+'validation/'\n","\n","# #all letters source dir\n","# a_source_dir=source_dir+'A/'\n","# b_source_dir=source_dir+'B/'\n","# c_source_dir=source_dir+'C/'\n","# d_source_dir=source_dir+'D/'\n","# e_source_dir=source_dir+'E/'\n","# f_source_dir=source_dir+'F/'\n","# g_source_dir=source_dir+'G/'\n","# h_source_dir=source_dir+'H/'\n","# i_source_dir=source_dir+'I/'\n","# j_source_dir=source_dir+'J/'\n","# k_source_dir=source_dir+'K/'\n","# l_source_dir=source_dir+'L/'\n","# m_source_dir=source_dir+'M/'\n","# n_source_dir=source_dir+'N/'\n","# o_source_dir=source_dir+'O/'\n","# p_source_dir=source_dir+'P/'\n","# q_source_dir=source_dir+'Q/'\n","# r_source_dir=source_dir+'R/'\n","# s_source_dir=source_dir+'S/'\n","# t_source_dir=source_dir+'T/'\n","# u_source_dir=source_dir+'U/'\n","# v_source_dir=source_dir+'V/'\n","# w_source_dir=source_dir+'W/'\n","# x_source_dir=source_dir+'X/'\n","# y_source_dir=source_dir+'Y/'\n","# z_source_dir=source_dir+'Z/'\n","\n","# #all letters training dir paths\n","# a_train_dir=train_dir+'A/'\n","# b_train_dir=train_dir+'B/'\n","# c_train_dir=train_dir+'C/'\n","# d_train_dir=train_dir+'D/'\n","# e_train_dir=train_dir+'E/'\n","# f_train_dir=train_dir+'F/'\n","# g_train_dir=train_dir+'G/'\n","# h_train_dir=train_dir+'H/'\n","# i_train_dir=train_dir+'I/'\n","# j_train_dir=train_dir+'J/'\n","# k_train_dir=train_dir+'K/'\n","# l_train_dir=train_dir+'L/'\n","# m_train_dir=train_dir+'M/'\n","# n_train_dir=train_dir+'N/'\n","# o_train_dir=train_dir+'O/'\n","# p_train_dir=train_dir+'P/'\n","# q_train_dir=train_dir+'Q/'\n","# r_train_dir=train_dir+'R/'\n","# s_train_dir=train_dir+'S/'\n","# t_train_dir=train_dir+'T/'\n","# u_train_dir=train_dir+'U/'\n","# v_train_dir=train_dir+'V/'\n","# w_train_dir=train_dir+'W/'\n","# x_train_dir=train_dir+'X/'\n","# y_train_dir=train_dir+'Y/'\n","# z_train_dir=train_dir+'Z/'\n","\n","# #all letters validation dir paths\n","# a_val_dir=val_dir+'A/'\n","# b_val_dir=val_dir+'B/'\n","# c_val_dir=val_dir+'C/'\n","# d_val_dir=val_dir+'D/'\n","# e_val_dir=val_dir+'E/'\n","# f_val_dir=val_dir+'F/'\n","# g_val_dir=val_dir+'G/'\n","# h_val_dir=val_dir+'H/'\n","# i_val_dir=val_dir+'I/'\n","# j_val_dir=val_dir+'J/'\n","# k_val_dir=val_dir+'K/'\n","# l_val_dir=val_dir+'L/'\n","# m_val_dir=val_dir+'M/'\n","# n_val_dir=val_dir+'N/'\n","# o_val_dir=val_dir+'O/'\n","# p_val_dir=val_dir+'P/'\n","# q_val_dir=val_dir+'Q/'\n","# r_val_dir=val_dir+'R/'\n","# s_val_dir=val_dir+'S/'\n","# t_val_dir=val_dir+'T/'\n","# u_val_dir=val_dir+'U/'\n","# v_val_dir=val_dir+'V/'\n","# w_val_dir=val_dir+'W/'\n","# x_val_dir=val_dir+'X/'\n","# y_val_dir=val_dir+'Y/'\n","# z_val_dir=val_dir+'Z/'\n","\n","# #list of all source dir\n","# ALL_SOURCE=[a_source_dir,\n","# b_source_dir,\n","# c_source_dir,\n","# d_source_dir,\n","# e_source_dir,\n","# f_source_dir,\n","# g_source_dir,\n","# h_source_dir,\n","# i_source_dir,\n","# j_source_dir,\n","# k_source_dir,\n","# l_source_dir,\n","# m_source_dir,\n","# n_source_dir,\n","# o_source_dir,\n","# p_source_dir,\n","# q_source_dir,\n","# r_source_dir,\n","# s_source_dir,\n","# t_source_dir,\n","# u_source_dir,\n","# v_source_dir,\n","# w_source_dir,\n","# x_source_dir,\n","# y_source_dir,\n","# z_source_dir\n","# ]\n","\n","# #list of all train dir\n","# ALL_TRAIN=[a_train_dir,\n","# b_train_dir,\n","# c_train_dir,\n","# d_train_dir,\n","# e_train_dir,\n","# f_train_dir,\n","# g_train_dir,\n","# h_train_dir,\n","# i_train_dir,\n","# j_train_dir,\n","# k_train_dir,\n","# l_train_dir,\n","# m_train_dir,\n","# n_train_dir,\n","# o_train_dir,\n","# p_train_dir,\n","# q_train_dir,\n","# r_train_dir,\n","# s_train_dir,\n","# t_train_dir,\n","# u_train_dir,\n","# v_train_dir,\n","# w_train_dir,\n","# x_train_dir,\n","# y_train_dir,\n","# z_train_dir,]\n","\n","# #list of all val dir\n","# ALL_VAL=[a_val_dir,\n","# b_val_dir,\n","# c_val_dir,\n","# d_val_dir,\n","# e_val_dir,\n","# f_val_dir,\n","# g_val_dir,\n","# h_val_dir,\n","# i_val_dir,\n","# j_val_dir,\n","# k_val_dir,\n","# l_val_dir,\n","# m_val_dir,\n","# n_val_dir,\n","# o_val_dir,\n","# p_val_dir,\n","# q_val_dir,\n","# r_val_dir,\n","# s_val_dir,\n","# t_val_dir,\n","# u_val_dir,\n","# v_val_dir,\n","# w_val_dir,\n","# x_val_dir,\n","# y_val_dir,\n","# z_val_dir,]"]},{"cell_type":"markdown","metadata":{"id":"1RAmU3DgfH9N"},"source":["Train and test split"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QL1hQicPfHh6"},"outputs":[],"source":["# #function to split data\n","# def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n","#   files = []\n","#   for filename in os.listdir(SOURCE_DIR):\n","#       file = SOURCE_DIR + filename\n","#       if os.path.getsize(file) > 0:\n","#           files.append(filename)\n","#       else:\n","#           print(filename + \" is zero length, so ignoring.\")\n","\n","#   training_length = int(len(files) * SPLIT_SIZE)\n","#   testing_length = int(len(files) - training_length)\n","#   shuffled_set = random.sample(files, len(files))\n","#   training_set = shuffled_set[0:training_length]\n","#   testing_set = shuffled_set[-testing_length:]\n","\n","#   for filename in training_set:\n","#       this_file = SOURCE_DIR + filename\n","#       destination = TRAINING_DIR + filename\n","#       copyfile(this_file, destination)\n","\n","#   for filename in testing_set:\n","#       this_file = SOURCE_DIR + filename\n","#       destination = VALIDATION_DIR + filename\n","#       copyfile(this_file, destination)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"WfvH7DJiefaK"},"outputs":[],"source":["# split_size=0.8\n","# for i in range(26):\n","#   split_data(ALL_SOURCE[i],ALL_TRAIN[i],ALL_VAL[i],split_size)"]},{"cell_type":"markdown","metadata":{"id":"ZWmWYvgVfRPF"},"source":["Image Data Generator"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"R7QhQpe3efYH"},"outputs":[],"source":["def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n","  train_datagen = ImageDataGenerator(rescale=1/255)\n","  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n","                                                      batch_size=256,\n","                                                      class_mode='categorical',\n","                                                      target_size=(200,200))\n"," \n","  validation_datagen = ImageDataGenerator(rescale=1/255,\n","                                     rotation_range=40,\n","                                     width_shift_range=0.2,\n","                                     height_shift_range=0.2,\n","                                     shear_range=0.2,\n","                                     zoom_range=0.2,\n","                                     horizontal_flip=True,\n","                                     fill_mode='nearest')\n","  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n","                                                                batch_size=256,\n","                                                                class_mode='categorical',\n","                                                                target_size=(200,200))\n","  return train_generator, validation_generator"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"AHk4RaQPefVv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 9299 images belonging to 26 classes.\n","Found 3602 images belonging to 26 classes.\n"]}],"source":["train_generator, validation_generator = train_val_generators(train_dir,val_dir)"]},{"cell_type":"markdown","metadata":{"id":"PFXZp8fVffS7"},"source":["Model building"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"f3mjlHi9efTc"},"outputs":[],"source":["#parameters\n","img_height=200\n","img_width=200\n","num_classes=26\n","do=0.5\n","reg=tf.keras.regularizers.l2(l2=0.0015)\n","batch_size=256\n","epochs=20"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CP4aS1uDefOq"},"outputs":[],"source":["def create_model():\n","  model = Sequential([\n","    Conv2D(16, (15,15), activation='relu',input_shape=(img_height, img_width, 3)),\n","    MaxPooling2D(2,2),\n","    Conv2D(32, (15,15),  activation='relu'),\n","    MaxPooling2D(2,2),\n","    Conv2D(64, (15,15),  activation='relu'),\n","    MaxPooling2D(2,2),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","    ])\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","  return model"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"vNhqMKHmefC1"},"outputs":[],"source":["model=create_model()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"61r8Yjsef-be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 186, 186, 16)      10816     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 93, 93, 16)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 79, 79, 32)        115232    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 39, 39, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 25, 25, 64)        460864    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 9216)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               1179776   \n","                                                                 \n"," dense_1 (Dense)             (None, 26)                3354      \n","                                                                 \n","=================================================================\n","Total params: 1,770,042\n","Trainable params: 1,770,042\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"CVC-A9JMguly"},"outputs":[],"source":["callbacks=keras.callbacks.ModelCheckpoint('./../checkpoints/checkpoint-{epoch}.h5', save_best_only=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9SJs9f4OgEex"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","37/37 - 76s - loss: 3.2876 - accuracy: 0.0393 - val_loss: 3.2533 - val_accuracy: 0.0469 - 76s/epoch - 2s/step\n","Epoch 2/20\n","37/37 - 74s - loss: 3.1617 - accuracy: 0.0604 - val_loss: 3.1919 - val_accuracy: 0.0625 - 74s/epoch - 2s/step\n","Epoch 3/20\n","37/37 - 75s - loss: 3.0721 - accuracy: 0.0741 - val_loss: 3.1349 - val_accuracy: 0.0630 - 75s/epoch - 2s/step\n","Epoch 4/20\n","37/37 - 74s - loss: 3.0054 - accuracy: 0.0927 - val_loss: 3.0891 - val_accuracy: 0.0836 - 74s/epoch - 2s/step\n","Epoch 5/20\n","37/37 - 75s - loss: 2.9613 - accuracy: 0.1096 - val_loss: 3.1581 - val_accuracy: 0.0888 - 75s/epoch - 2s/step\n","Epoch 6/20\n","37/37 - 74s - loss: 2.8868 - accuracy: 0.1312 - val_loss: 3.0744 - val_accuracy: 0.0911 - 74s/epoch - 2s/step\n","Epoch 7/20\n","37/37 - 75s - loss: 2.7381 - accuracy: 0.1665 - val_loss: 3.0343 - val_accuracy: 0.1124 - 75s/epoch - 2s/step\n","Epoch 8/20\n","37/37 - 74s - loss: 2.6217 - accuracy: 0.1922 - val_loss: 3.0253 - val_accuracy: 0.1083 - 74s/epoch - 2s/step\n","Epoch 9/20\n","37/37 - 74s - loss: 2.4966 - accuracy: 0.2236 - val_loss: 2.9374 - val_accuracy: 0.1524 - 74s/epoch - 2s/step\n","Epoch 10/20\n","37/37 - 75s - loss: 2.4504 - accuracy: 0.2485 - val_loss: 3.0349 - val_accuracy: 0.1499 - 75s/epoch - 2s/step\n","Epoch 11/20\n","37/37 - 75s - loss: 2.2371 - accuracy: 0.3127 - val_loss: 2.9982 - val_accuracy: 0.1710 - 75s/epoch - 2s/step\n","Epoch 12/20\n","37/37 - 75s - loss: 2.0947 - accuracy: 0.3557 - val_loss: 3.0506 - val_accuracy: 0.1774 - 75s/epoch - 2s/step\n","Epoch 13/20\n","37/37 - 75s - loss: 1.9713 - accuracy: 0.3947 - val_loss: 3.0538 - val_accuracy: 0.1802 - 75s/epoch - 2s/step\n","Epoch 14/20\n","37/37 - 74s - loss: 1.8468 - accuracy: 0.4335 - val_loss: 3.1720 - val_accuracy: 0.1907 - 74s/epoch - 2s/step\n","Epoch 15/20\n","37/37 - 74s - loss: 1.7155 - accuracy: 0.4754 - val_loss: 3.3442 - val_accuracy: 0.2032 - 74s/epoch - 2s/step\n","Epoch 16/20\n","37/37 - 73s - loss: 1.5802 - accuracy: 0.5097 - val_loss: 3.4960 - val_accuracy: 0.2043 - 73s/epoch - 2s/step\n","Epoch 17/20\n","37/37 - 74s - loss: 1.5193 - accuracy: 0.5369 - val_loss: 3.5277 - val_accuracy: 0.1904 - 74s/epoch - 2s/step\n","Epoch 18/20\n","37/37 - 74s - loss: 1.3758 - accuracy: 0.5791 - val_loss: 3.8135 - val_accuracy: 0.2002 - 74s/epoch - 2s/step\n","Epoch 19/20\n","37/37 - 74s - loss: 1.2781 - accuracy: 0.6099 - val_loss: 3.9452 - val_accuracy: 0.2041 - 74s/epoch - 2s/step\n","Epoch 20/20\n","37/37 - 74s - loss: 1.1763 - accuracy: 0.6417 - val_loss: 4.3766 - val_accuracy: 0.2115 - 74s/epoch - 2s/step\n"]}],"source":["history = model.fit(\n","    train_generator,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    validation_data=validation_generator,\n","    verbose=2, #if hvd.rank() == 0 else 0,\n","    callbacks=callbacks\n",")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM81C9w1diQNinA7BHTJGWi","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
