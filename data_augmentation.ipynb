{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e05242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8baf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from skimage import io\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adf205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ee5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016c2ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUES = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f62f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main_dir='C:/Users/Anusha/ML Mini Project/'\n",
    "# #source and dest dir\n",
    "# source_dir=main_dir+'source'\n",
    "# dest_dir=main_dir+'sign_letters'\n",
    "# os.mkdir(source_dir)\n",
    "# os.mkdir(dest_dir)\n",
    "# for dir1 in values:\n",
    "#     path=os.path.join(source_dir,dir1)\n",
    "#     os.mkdir(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440dc38a",
   "metadata": {},
   "source": [
    "All directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7930d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all directories\n",
    "main_dir='C:/Users/Anusha/ML Mini Project/'\n",
    "\n",
    "source_dir=main_dir+'source/'\n",
    "dest_dir=main_dir+'sign_letters/'\n",
    "\n",
    "\n",
    "train_dir=dest_dir+'training/'\n",
    "val_dir=dest_dir+'validation/'\n",
    "\n",
    "#all letters source dir\n",
    "a_source_dir=source_dir+'A/'\n",
    "b_source_dir=source_dir+'B/'\n",
    "c_source_dir=source_dir+'C/'\n",
    "d_source_dir=source_dir+'D/'\n",
    "e_source_dir=source_dir+'E/'\n",
    "f_source_dir=source_dir+'F/'\n",
    "g_source_dir=source_dir+'G/'\n",
    "h_source_dir=source_dir+'H/'\n",
    "i_source_dir=source_dir+'I/'\n",
    "j_source_dir=source_dir+'J/'\n",
    "k_source_dir=source_dir+'K/'\n",
    "l_source_dir=source_dir+'L/'\n",
    "m_source_dir=source_dir+'M/'\n",
    "n_source_dir=source_dir+'N/'\n",
    "o_source_dir=source_dir+'O/'\n",
    "p_source_dir=source_dir+'P/'\n",
    "q_source_dir=source_dir+'Q/'\n",
    "r_source_dir=source_dir+'R/'\n",
    "s_source_dir=source_dir+'S/'\n",
    "t_source_dir=source_dir+'T/'\n",
    "u_source_dir=source_dir+'U/'\n",
    "v_source_dir=source_dir+'V/'\n",
    "w_source_dir=source_dir+'W/'\n",
    "x_source_dir=source_dir+'X/'\n",
    "y_source_dir=source_dir+'Y/'\n",
    "z_source_dir=source_dir+'Z/'\n",
    "\n",
    "#all letters training dir paths\n",
    "a_train_dir=train_dir+'A/'\n",
    "b_train_dir=train_dir+'B/'\n",
    "c_train_dir=train_dir+'C/'\n",
    "d_train_dir=train_dir+'D/'\n",
    "e_train_dir=train_dir+'E/'\n",
    "f_train_dir=train_dir+'F/'\n",
    "g_train_dir=train_dir+'G/'\n",
    "h_train_dir=train_dir+'H/'\n",
    "i_train_dir=train_dir+'I/'\n",
    "j_train_dir=train_dir+'J/'\n",
    "k_train_dir=train_dir+'K/'\n",
    "l_train_dir=train_dir+'L/'\n",
    "m_train_dir=train_dir+'M/'\n",
    "n_train_dir=train_dir+'N/'\n",
    "o_train_dir=train_dir+'O/'\n",
    "p_train_dir=train_dir+'P/'\n",
    "q_train_dir=train_dir+'Q/'\n",
    "r_train_dir=train_dir+'R/'\n",
    "s_train_dir=train_dir+'S/'\n",
    "t_train_dir=train_dir+'T/'\n",
    "u_train_dir=train_dir+'U/'\n",
    "v_train_dir=train_dir+'V/'\n",
    "w_train_dir=train_dir+'W/'\n",
    "x_train_dir=train_dir+'X/'\n",
    "y_train_dir=train_dir+'Y/'\n",
    "z_train_dir=train_dir+'Z/'\n",
    "\n",
    "#all letters validation dir paths\n",
    "a_val_dir=val_dir+'A/'\n",
    "b_val_dir=val_dir+'B/'\n",
    "c_val_dir=val_dir+'C/'\n",
    "d_val_dir=val_dir+'D/'\n",
    "e_val_dir=val_dir+'E/'\n",
    "f_val_dir=val_dir+'F/'\n",
    "g_val_dir=val_dir+'G/'\n",
    "h_val_dir=val_dir+'H/'\n",
    "i_val_dir=val_dir+'I/'\n",
    "j_val_dir=val_dir+'J/'\n",
    "k_val_dir=val_dir+'K/'\n",
    "l_val_dir=val_dir+'L/'\n",
    "m_val_dir=val_dir+'M/'\n",
    "n_val_dir=val_dir+'N/'\n",
    "o_val_dir=val_dir+'O/'\n",
    "p_val_dir=val_dir+'P/'\n",
    "q_val_dir=val_dir+'Q/'\n",
    "r_val_dir=val_dir+'R/'\n",
    "s_val_dir=val_dir+'S/'\n",
    "t_val_dir=val_dir+'T/'\n",
    "u_val_dir=val_dir+'U/'\n",
    "v_val_dir=val_dir+'V/'\n",
    "w_val_dir=val_dir+'W/'\n",
    "x_val_dir=val_dir+'X/'\n",
    "y_val_dir=val_dir+'Y/'\n",
    "z_val_dir=val_dir+'Z/'\n",
    "\n",
    "#list of all source dir\n",
    "ALL_SOURCE=[a_source_dir,\n",
    "b_source_dir,\n",
    "c_source_dir,\n",
    "d_source_dir,\n",
    "e_source_dir,\n",
    "f_source_dir,\n",
    "g_source_dir,\n",
    "h_source_dir,\n",
    "i_source_dir,\n",
    "j_source_dir,\n",
    "k_source_dir,\n",
    "l_source_dir,\n",
    "m_source_dir,\n",
    "n_source_dir,\n",
    "o_source_dir,\n",
    "p_source_dir,\n",
    "q_source_dir,\n",
    "r_source_dir,\n",
    "s_source_dir,\n",
    "t_source_dir,\n",
    "u_source_dir,\n",
    "v_source_dir,\n",
    "w_source_dir,\n",
    "x_source_dir,\n",
    "y_source_dir,\n",
    "z_source_dir,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12e72c",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "\n",
    "1.Source --> A,B,C....Z\n",
    "   Each with 20 images **(Done)**\n",
    "    \n",
    "   Rename such that they have their names as 'letter_(anything)' e.g 'A_0_..' or 'A_123'. (It should start with 'A_')**(Done)**\n",
    "    \n",
    "2.Augment images within source\n",
    "\n",
    "   Each image giving 20-25 images\n",
    "   \n",
    "   Now a total of 400-500 images in a single letter in source\n",
    " \n",
    "3.We'll split them to training and validation dataset\n",
    "\n",
    "4.Create model and give training data as input where image augmentation will again be used.\n",
    "\n",
    "5.We'll test with validation data\n",
    "\n",
    "6.Plot the training and validation accuracy and losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9605b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming images\n",
    "def main():\n",
    "    folder='source'\n",
    "    for count,sub in enumerate(os.listdir(folder)):\n",
    "        subfolder=sub\n",
    "        for val,file in enumerate(os.listdir(os.path.join(folder,subfolder))):\n",
    "            name = f\"{subfolder}_{val}.jpg\"\n",
    "            src =f\"{os.path.join(folder,subfolder)}/{file}\"  \n",
    "            dst =f\"{os.path.join(folder,subfolder)}/{name}\"\n",
    "            os.rename(src,dst)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a10476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmenting images within source\n",
    "# VALUES_1=['A','B','C','D','E','F','L','M','N','O','R','S','T','V','W','X','Y','Z']\n",
    "# VALUES_2=['G','H','I','J','K','P','Q','U']\n",
    "datagen=ImageDataGenerator(rescale=1/255,\n",
    "                         rotation_range=30,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         shear_range=0.15,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True,\n",
    "                         fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a58320",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6092/3736132349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         for batch in datagen.flow(x,\n\u001b[0m\u001b[0;32m      9\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                             \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             x = self.image_data_generator.apply_transform(\n\u001b[0m\u001b[0;32m    802\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m         x = apply_affine_transform(\n\u001b[0m\u001b[0;32m   2012\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m             \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"theta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2607\u001b[0m         \u001b[0mfinal_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m         channel_images = [\n\u001b[0m\u001b[0;32m   2610\u001b[0m             ndimage.interpolation.affine_transform(\n\u001b[0;32m   2611\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2609\u001b[0m         channel_images = [\n\u001b[1;32m-> 2610\u001b[1;33m             ndimage.interpolation.affine_transform(\n\u001b[0m\u001b[0;32m   2611\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m                 \u001b[0mfinal_affine_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    609\u001b[0m                              mode, cval, npad, False)\n\u001b[0;32m    610\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0m\u001b[0;32m    612\u001b[0m                                       \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                                       None)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder='source'\n",
    "for i,let in enumerate(VALUES[2:]):\n",
    "    DIR=os.path.join(folder,let)+'/'\n",
    "    for j,img in enumerate(os.listdir(DIR)):     \n",
    "        x=io.imread(os.path.join(DIR,img))\n",
    "        x=x.reshape((1,)+x.shape)\n",
    "        p=0\n",
    "        for batch in datagen.flow(x,\n",
    "                            batch_size=10,\n",
    "                            save_to_dir=DIR,\n",
    "                            save_prefix=let,\n",
    "                            save_format='jpg'):\n",
    "            p=p+1\n",
    "            if p>3:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d31c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder='source'\n",
    "# let='C'\n",
    "# for i,file in enumerate(os.listdir(c_source_dir)):\n",
    "#     x=io.imread(folder+'/'+let+'/'+file)\n",
    "#     x=x.reshape((1,)+x.shape)\n",
    "#     p=0\n",
    "#     for batch in datagen.flow(x,\n",
    "#                         batch_size=20,\n",
    "#                         save_to_dir=c_source_dir,\n",
    "#                         save_prefix='C',\n",
    "#                         save_format='jpg'):\n",
    "#         p=p+1\n",
    "#         if p>9:\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be99a06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Anusha/ML Mini Project/source/C/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addec8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_0.jpg',\n",
       " 'C_1.jpg',\n",
       " 'C_10.jpg',\n",
       " 'C_11.jpg',\n",
       " 'C_12.jpg',\n",
       " 'C_13.jpg',\n",
       " 'C_14.jpg',\n",
       " 'C_15.jpg',\n",
       " 'C_16.jpg',\n",
       " 'C_17.jpg',\n",
       " 'C_18.jpg',\n",
       " 'C_19.jpg',\n",
       " 'C_2.jpg',\n",
       " 'C_3.jpg',\n",
       " 'C_4.jpg',\n",
       " 'C_5.jpg',\n",
       " 'C_6.jpg',\n",
       " 'C_7.jpg',\n",
       " 'C_8.jpg',\n",
       " 'C_9.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(c_source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(ALL_SOURCE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cfdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dece5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split data\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  files = []\n",
    "  for filename in os.listdir(SOURCE_DIR):\n",
    "      file = SOURCE_DIR + filename\n",
    "      if os.path.getsize(file) > 0:\n",
    "          files.append(filename)\n",
    "      else:\n",
    "          print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "  training_length = int(len(files) * SPLIT_SIZE)\n",
    "  testing_length = int(len(files) - training_length)\n",
    "  shuffled_set = random.sample(files, len(files))\n",
    "  training_set = shuffled_set[0:training_length]\n",
    "  testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "  for filename in training_set:\n",
    "      this_file = SOURCE_DIR + filename\n",
    "      destination = TRAINING_DIR + filename\n",
    "      copyfile(this_file, destination)\n",
    "\n",
    "  for filename in testing_set:\n",
    "      this_file = SOURCE_DIR + filename\n",
    "      destination = VALIDATION_DIR + filename\n",
    "      copyfile(this_file, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size=0.8\n",
    "split_data(h_source_dir,h_train_dir,h_val_dir,split_size)\n",
    "#finished till h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[]\n",
    "for i,val in enumerate(VALUES):\n",
    "    values.append(val.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e182046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, SAV_TRAIN_DIR, SAV_VAL_DIR,LTR):\n",
    " \n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
    "  train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                     rotation_range=40,\n",
    "                                     width_shift_range=0.2,\n",
    "                                     height_shift_range=0.2,\n",
    "                                     shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=100,\n",
    "                                                      target_size=(150,150),\n",
    "                                                      save_to_dir=SAV_TRAIN_DIR,\n",
    "                                                      save_format='jpg',\n",
    "                                                      save_prefix=LTR)\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=100,\n",
    "                                                                target_size=(150,150),\n",
    "                                                                save_to_dir=SAV_VAL_DIR,\n",
    "                                                                save_format='jpg',\n",
    "                                                                save_prefix=LTR)\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96738835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = train_val_generators(train_dir, val_dir,'a_train_dir','a_val_dir','A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb02151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3b61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
